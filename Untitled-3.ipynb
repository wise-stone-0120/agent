{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "85c330a7",
   "metadata": {},
   "source": [
    "# PDF 읽고 내용 추출하기\n",
    "Linkedin.pdf 하나 만들어놓고 시작한다.\n",
    "\n",
    "summary.txt에 내용은 적어놓고."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de1e0a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ModuleNotFoundError: No module named 'pypdf'\n",
    "# pypdf를 설치해야 한다.\n",
    "%pip install pypdf\n",
    "# gradio도 설치\n",
    "%pip install gradio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4920660",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 일단 import는 해야지.\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from pypdf import PdfReader\n",
    "import gradio as gr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f54319d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 늘 하는 거\n",
    "load_dotenv(override=True)\n",
    "openai = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f95e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = PdfReader(\"me/InseokPark.pdf\")\n",
    "linkedin = \"\"\n",
    "for page in reader.pages:\n",
    "    text = page.extract_text()\n",
    "    if text:\n",
    "        linkedin += text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f46af9ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(linkedin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef2bff6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"me/aboutMe.txt\", \"r\", encoding=\"utf-8\") as f:\n",
    "    summary = f.read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "893e12ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "name = \"Inseok Park\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42857d93",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt = f\"You are acting as {name}. You are answering questions on {name}'s website. \\\n",
    "    particularly questions related to {name}'s career, background, skills and experience. \\\n",
    "    Your responsibility is to represent {name} for interactions on the website as faithfully as possible. \\\n",
    "    You are given a summary of {name}'s background and linkedIn profile which you can use to answer questions. \\\n",
    "    Be professional and engaing, as if talking to a potential client or future employer who came across the website. \\\n",
    "    If you don't know the answer, say so.\"\n",
    "\n",
    "system_prompt += f\"\\n\\n## Summary:{summary}\\n\\n## LinkedIn Profile:{linkedin}\\n\\n\"\n",
    "system_prompt += f\"With this context, please chat with the user, always staying in character as {name}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57dd9a2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "system_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9daca1ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "def chat(message, history):\n",
    "    message = [{\"role\":\"system\", \"content\":system_prompt}] + history + [{\"role\":\"user\", \"content\":message}]\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=message\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44a96710",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12389edd",
   "metadata": {},
   "source": [
    "## 이제 응용해서 해본다.\n",
    "1. LLM한테 질문을 평가해보라고 하고\n",
    "2. 평가해서 bad가 나오면 다시 실행하라고 하고\n",
    "3. 요걸 반복하게 한다.\n",
    "\n",
    "all without Agentic framework!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ecd613f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pydantic model 작성\n",
    "from pydantic import BaseModel\n",
    "\n",
    "class Evaluation(BaseModel):\n",
    "    is_acceptable: bool\n",
    "    feedback: str"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9720c5a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluater의 system 프롬프트 (고정 string)\n",
    "evaluator_system_prompt = f\"You are an evaluator who deciedes whether a response for a question is acceptable. \\\n",
    "You are provided with a conversation between a user and an agent. Your task is to decide \\\n",
    "whether the Agent's latest response is acceptable quality. \\\n",
    "The Agent is playing the role of {name} and is representing {name} on their website. \\\n",
    "The Agent has been instructed to be professional and engaging, as if talking to a potencial customer or \\\n",
    "future employer who came accros the website. \\\n",
    "The Agent has been provided with context on {name} in the form of their summary and linkedIn profile. \\\n",
    "Here is the information:\"\n",
    "\n",
    "evaluator_system_prompt += f\"\\n\\n## Summary:\\n{summary}\\n\\n## LinkedIn Profile:\\n{linkedin}\\n\\n\"\n",
    "evaluator_system_prompt += f\"With this context, please evaluate the latest response, replying with \\\n",
    "    whether the response is acceptable and your feedback.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9d25cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluater의 유저 프롬프트 작성 함수\n",
    "def evaluater_user_prompt(rely, history, message):\n",
    "    user_prompt = f\"Here is the conversation between the user and the Agent:\\n{history} \\n\\n \\\n",
    "        Here is the latest message from the user:\\n{message}\\n\\n \\\n",
    "        Here is the latest respnse from the Agent:\\n{rely} \\n\\n \\\n",
    "        Please evaluate the response, replying with whether it is acceptable and your feedback.\"\n",
    "    return user_prompt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b2a5f21",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gemini 인스턴스를 생성하고\n",
    "import os\n",
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "gemini = OpenAI(\n",
    "    api_key=os.getenv(\"GEMINI_API_KEY\"),\n",
    "    base_url=GEMINI_BASE_URL\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d294c2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gemini야, evaluate를 해야지. \n",
    "def evaluate(rely, message, history) -> Evaluation:\n",
    "    message = ([{\"role\":\"system\", \"content\":evaluator_system_prompt}] + \n",
    "               [{\"role\":\"user\", \"content\":evaluater_user_prompt(rely, history, message)}])\n",
    "    response = gemini.beta.chat.completions.parse(model=\"gemini-2.0-flash\", messages=message, response_format=Evaluation)\n",
    "    return response.choices[0].message.parsed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3261028a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# openai 답이 틀렸으면, 다시 답해야지\n",
    "def rerun(reply, message, history, feedback):\n",
    "    # system prompt로 답이 틀렸다고 알려야지.\n",
    "    updated_sys_prompt = system_prompt + f\"\\n\\n Your previous response is rejected.\\nYou just tried to reply, \\\n",
    "        but the quality control rejected your reply.\\n \\\n",
    "        Your attempted answer:\\n{reply}\\n\\n \\\n",
    "        Reason for rejection:\\n{feedback}\\n\\n\"\n",
    "    messages = ([{\"role\":\"system\", \"content\":updated_sys_prompt}]\n",
    "                + history\n",
    "                + [{\"role\":\"user\", \"content\":message}])\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba30a225",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pydantic model에서 사용할 chat 작성\n",
    "# message:user 질문\n",
    "# history: 여태껏 대화내용\n",
    "def chat(message, history):\n",
    "    if \"patent\" in message:\n",
    "        system = system_prompt + \"\\n\\n everything you answer needs to be in pig latin. \\\n",
    "            It is madatory that you respond only and entirely in pig latin.\"\n",
    "    else:\n",
    "        system = system_prompt\n",
    "    messages = ([{\"role\":\"system\", \"content\":system}]\n",
    "                + history \n",
    "                + [{\"role\":\"user\", \"content\":message}])\n",
    "    response = openai.chat.completions.create(\n",
    "        model=\"gpt-4o-mini\",\n",
    "        messages=messages\n",
    "    )\n",
    "    reply = response.choices[0].message.content\n",
    "\n",
    "    # evaluate시켜야지. gemini한테\n",
    "    evaluation = evaluate(reply, message, history)\n",
    "\n",
    "    #\n",
    "    if evaluation.is_acceptable:\n",
    "        print(\"Passed evaluation - returning reply\")\n",
    "    else:\n",
    "        print(\"Failed evaluation - retry\")\n",
    "        print(f\"reply:{reply}\\nmessage:{message}\\n\")\n",
    "        print(evaluation.feedback)\n",
    "        reply = rerun(reply, message, history, evaluation.feedback)\n",
    "    return reply "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffbe8b5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "gr.ChatInterface(chat, type=\"messages\").launch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
