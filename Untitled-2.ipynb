{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f17bde82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# anthropic 모듈이 설치되야지.\n",
    "%pip install anthropic\n",
    "\n",
    "# import \n",
    "import os\n",
    "import json\n",
    "from dotenv import load_dotenv\n",
    "from openai import OpenAI\n",
    "from anthropic import Anthropic\n",
    "from IPython.display import Markdown, display"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fefcc354",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 요거는 항상 필요하지\n",
    "load_dotenv(override = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ca6141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# API KEY prefix 찍어보기\n",
    "openai_api_key = os.getenv('OPENAI_API_KEY')\n",
    "anthropic_api_key = os.getenv('ANTHROPIC_API_KEY')\n",
    "google_api_key = os.getenv('GOOGLE_API_KEY')\n",
    "deepseek_api_key = os.getenv('DEEPSEEK_API_KEY')\n",
    "groq_api_key = os.getenv('GROQ_API_KEY')\n",
    "\n",
    "if openai_api_key:\n",
    "    print(f\"OpenAI API key exists and begins {openai_api_key[:8]}\")\n",
    "else:\n",
    "    print(\"OpenAI API key is not set.\")\n",
    "\n",
    "if anthropic_api_key:\n",
    "    print(f\"Anthropic API key exists and begins {anthropic_api_key[:7]}\")\n",
    "else:\n",
    "    print(\"Anthropic API key is not set. This is optional.\")\n",
    "\n",
    "if google_api_key:\n",
    "    print(f\"Google API key exists and begins {google_api_key[:2]}\")\n",
    "else:\n",
    "    print(\"Google API key is not set. This is optional.\")\n",
    "\n",
    "if deepseek_api_key:\n",
    "    print(f\"Deepseek API key exists and begins {deepseek_api_key[:3]}\")\n",
    "else:\n",
    "    print(\"Deepseek API key is not set. This is optional.\")\n",
    "\n",
    "if groq_api_key:\n",
    "    print(f\"Groq API key exists and begins {groq_api_key[:4]}\")\n",
    "else:\n",
    "    print(\"Groq API key is not set. This is optional.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10614b51",
   "metadata": {},
   "outputs": [],
   "source": [
    "# LLM 대상 질문을 만들어줘.\n",
    "request = \"please come up with a challenging, nuanced question that I can ask a number of LLMs \\\n",
    "    to evaluate their intellegence. \\\n",
    "    Answer only with the question, no other explanations.\"\n",
    "message = [{\"role\":\"user\", \"content\":request}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2ff01dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 만든 message 한번 확인\n",
    "message"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b049cf7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# gpt-4.1-mini, 니가 질문 만들어라.\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"gpt-4.1-mini\",\n",
    "    messages=message\n",
    ")\n",
    "\n",
    "# 만든 질문이 요렇게 생겼네.\n",
    "question = response.choices[0].message.content\n",
    "display(Markdown(question))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6534348",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 답변 받을 변수들을 정리하고,\n",
    "competitors=[]\n",
    "answers=[]\n",
    "message=[{\"role\":\"user\", \"content\":question}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e88bf3f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAI 부터 질문 시작\n",
    "model_name=\"gpt-4.1-mini\"\n",
    "response = openai.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=message\n",
    ")\n",
    "answer = response.choices[0].message.content\n",
    "display(Markdown(answer))\n",
    "\n",
    "# 답변은 차곡차곡 배열에 저장\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "383ec0fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이번엔 Anthropic\n",
    "model_name = \"claude-3-7-sonnet-latest\"\n",
    "\n",
    "# Anthropic은 다른 API사용.\n",
    "claude = Anthropic()\n",
    "response = claude.messages.create(\n",
    "    model=model_name,\n",
    "    messages=message,\n",
    "    max_tokens=1000\n",
    ")\n",
    "answer = response.content[0].text\n",
    "display(Markdown(answer))\n",
    "\n",
    "# 답변은 차곡차곡 배열에 쌓고,\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc429bf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이번에 Google\n",
    "model_name = \"gemini-2.0-flash\"\n",
    "\n",
    "# openai library 사용. base url은\n",
    "GEMINI_BASE_URL = \"https://generativelanguage.googleapis.com/v1beta/openai/\"\n",
    "openai = OpenAI(api_key=google_api_key, base_url=GEMINI_BASE_URL)\n",
    "\n",
    "response = openai.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=message\n",
    ")\n",
    "answer = response.choices[0].message.content\n",
    "display(Markdown(answer))\n",
    "\n",
    "# 답변은 차곡차곡 배열에 쌓고,\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "802c8bfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# DeepSeek도 해보자\n",
    "model_name = \"deepseek-chat\"\n",
    "\n",
    "# base url은\n",
    "DEEPSEEK_BASE_URL = \"https://api.deepseek.com/v1\"\n",
    "openai = OpenAI(api_key=deepseek_api_key, base_url=DEEPSEEK_BASE_URL)\n",
    "\n",
    "# call\n",
    "response = openai.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=message\n",
    ")\n",
    "\n",
    "# 답변은\n",
    "answer = response.choices[0].message.content\n",
    "display(Markdown(answer))\n",
    "\n",
    "# 답변은 차곡차곡 배열에 쌓고,\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17d985ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 마지막으로 groq\n",
    "model_name = \"llama-3.3-70b-versatile\"\n",
    "\n",
    "# base url은\n",
    "GROQ_BASE_URL = \"https://api.groq.com/openai/v1\"\n",
    "openai = OpenAI(api_key=groq_api_key, base_url=GROQ_BASE_URL)\n",
    "\n",
    "# call\n",
    "response = openai.chat.completions.create(\n",
    "    model=model_name,\n",
    "    messages=message\n",
    ")\n",
    "answer = response.choices[0].message.content\n",
    "display(Markdown(answer))\n",
    "\n",
    "# 답변은 차곡차곡 배열에 쌓고,\n",
    "competitors.append(model_name)\n",
    "answers.append(answer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb7d330f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ollama는 나중에"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c26cfa93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 쌓은 배열 한번 찍어보고\n",
    "print(competitors)\n",
    "print(answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e59cce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# zip을 이용해서 이쁘게 찍는다\n",
    "for competitor, answer in zip(competitors, answers):\n",
    "    print(f\"Competitor : {competitor}\\n\\n{answer}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "180689eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 이번엔 enumerate를 써서 찍는다\n",
    "together=\"\"\n",
    "for index, answer in enumerate(answers):\n",
    "    together += f\"# Response from competitor {index + 1}\\n\\n\"\n",
    "    together += answer + \"\\n\\n\"\n",
    "\n",
    "print(together)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa4d32b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 답변을 비교할 시간\n",
    "# 비교 prompt 작성하고\n",
    "judge = f\"\"\"You are judging a competition between {len(competitors)} competitors.\n",
    "Each model has been given this question.\n",
    "\n",
    "{message}\n",
    "\n",
    "Your job is to evaluate each response from clarity and strength of argument, \n",
    "and rank them in order of best of worst.\n",
    "Respond with JSON, and only JSON, with the following format:\n",
    "{{\"result\": [\"best competitor number\", \"seconde best competitor number\", ...]}}\n",
    "\n",
    "Here are the responses from each competitor:\n",
    "\n",
    "{together}\n",
    "\n",
    "Now respond with the JSON with the rank order of the competitors, nothing else.\n",
    "Do not include markdown formatting or code blocks.\n",
    "\"\"\"\n",
    "\n",
    "print(judge)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "555d8904",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\"result\": [\"2\", \"1\"]}\n"
     ]
    }
   ],
   "source": [
    "# 등수를 매기자\n",
    "judge_message = [{\"role\":\"user\", \"content\":judge}]\n",
    "\n",
    "openai = OpenAI()\n",
    "response = openai.chat.completions.create(\n",
    "    model=\"o3-mini\",\n",
    "    messages=judge_message\n",
    ")\n",
    "results = response.choices[0].message.content\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "809dc854",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rank 1 : gemini-2.0-flash\n",
      "Rank 2 : gpt-4.1-mini\n"
     ]
    }
   ],
   "source": [
    "# 등수를 예쁘게 표시하면\n",
    "result_dict = json.loads(results)\n",
    "ranks = result_dict[\"result\"]\n",
    "for index, result in enumerate(ranks):\n",
    "    competitor = competitors[int(result)-1]\n",
    "    print(f\"Rank {index+1} : {competitor}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
